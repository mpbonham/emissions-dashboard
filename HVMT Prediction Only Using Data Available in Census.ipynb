{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c227308",
   "metadata": {},
   "source": [
    "\n",
    "# HVMT Regression\n",
    "\n",
    "This notebook builds a robust **Household VMT (HVMT)** model using NHTS 2017 → train and 2022 → test.  \n",
    "It fixes common issues (column aliases, zero-VMT handling, year mismatches) and adds diagnostics:\n",
    "- Clean loaders with **alias mapping** (e.g., `NUMVEH` ↔ `HHVEHCNT`)\n",
    "- Create household `HH_VMT` from trip files and **merge**\n",
    "- Optional filtering of **zero-VMT** households\n",
    "- Train **Linear**, **Random Forest**, **XGBoost** (optionally **HistGradientBoosting** Poisson)\n",
    "- **Smearing correction** back to original scale\n",
    "- **Feature importances** (XGB), **residual plots**, and **segment analysis** (income, urban, vehicles)\n",
    "\n",
    "> Expected inputs in the working directory (or update paths):  \n",
    "> - `hhpub2017.csv`, `hhpub2022.csv` (household PUF)  \n",
    "> - `trippub2017.csv`, `trippub2022.csv` (trip PUF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f73df175",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 1: Imports & Config\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "except Exception:\n",
    "    XGBRegressor = None\n",
    "\n",
    "# HistGradientBoosting for Poisson regression\n",
    "try:\n",
    "    from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "except Exception:\n",
    "    HistGradientBoostingRegressor = None\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bcf0579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Paths (edit these if your files are in another folder)\n",
    "\n",
    "PATH_HH_2017 = \"hhpub2017.csv\"\n",
    "PATH_HH_2022 = \"hhpub2022.csv\"\n",
    "PATH_TR_2017 = \"trippub2017.csv\"\n",
    "PATH_TR_2022 = \"trippub2022.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d02e94f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 3: Loaders with alias mapping and cleaning\n",
    "\n",
    "# Canonical set used by modeling (you can add more later)\n",
    "CANON = [\"HHSIZE\",\"NUMVEH\",\"HHFAMINC\",\"URBAN\",\"HOMEOWN\",\"HOMETYPE\",\"HH_RACE\",\"HH_HISP\"]\n",
    "\n",
    "# Aliases to normalize cross-year differences\n",
    "ALIASES = {\n",
    "    \"HHSIZE\":   [\"HHSIZE\",\"HH_SIZE\",\"PERSONS\",\"NUMPERSONS\"],\n",
    "    \"NUMVEH\":   [\"HHVEHCNT\",\"NUMVEH\",\"VEHHO\",\"HH_NUMVEH\",\"VEH_CNT\"],\n",
    "    \"HHFAMINC\": [\"HHFAMINC\",\"HHINCOME\",\"HHFAMINC_IMPUTED\",\"HH_INC\",\"FAMINCOME\"],\n",
    "    \"URBAN\":    [\"URBAN\",\"URBRUR\",\"URBANSIZE\",\"URBAN_RURAL\",\"URBANCAT\"],\n",
    "    \"HOMEOWN\":  [\"HOMEOWN\",\"HOWND\",\"TENURE\",\"HH_OWN\",\"HOME_OWN\"],\n",
    "    \"HOMETYPE\": [\"HOMETYPE\",\"HSTRUCT\",\"UNITTYPE\",\"BLTYP\",\"HOME_TYPE\"],\n",
    "    \"HH_RACE\":  [\"HH_RACE\",\"HHRACE\",\"R_RACE\",\"RACE\",\"RACE1\"],\n",
    "    \"HH_HISP\":  [\"HH_HISP\",\"HHHISP\",\"HISPANIC\",\"HISP\",\"HISP1\"],\n",
    "}\n",
    "\n",
    "SENTINELS = {-9, -8, -7, -1}\n",
    "\n",
    "def normalize_household(path):\n",
    "    df = pd.read_csv(path)\n",
    "    if \"HOUSEID\" not in df.columns:\n",
    "        raise KeyError(f\"'HOUSEID' missing from {path}\")\n",
    "    # Build rename map by first matching alias per canonical\n",
    "    present = set(df.columns)\n",
    "    rename_map = {}\n",
    "    for canon, choices in ALIASES.items():\n",
    "        found = next((c for c in choices if c in present), None)\n",
    "        if found:\n",
    "            rename_map[found] = canon\n",
    "    df = df.rename(columns=rename_map)\n",
    "    keep_cols = [\"HOUSEID\"] + [c for c in CANON if c in df.columns]\n",
    "    df = df[keep_cols].copy()\n",
    "    # Replace sentinel values with NaN\n",
    "    df = df.replace(list(SENTINELS), np.nan)\n",
    "    return df\n",
    "\n",
    "def trips_to_hh_vmt(path):\n",
    "    t = pd.read_csv(path, usecols=[\"HOUSEID\",\"TRPMILES\"])\n",
    "    t[\"TRPMILES\"] = pd.to_numeric(t[\"TRPMILES\"], errors=\"coerce\")\n",
    "    t.loc[t[\"TRPMILES\"].isin(SENTINELS), \"TRPMILES\"] = np.nan\n",
    "    t = t.dropna(subset=[\"TRPMILES\"])\n",
    "    hh = t.groupby(\"HOUSEID\", as_index=False)[\"TRPMILES\"].sum().rename(columns={\"TRPMILES\":\"HH_VMT\"})\n",
    "    return hh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b5e59de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 households: 129696 | with VMT > 0: 117192\n",
      "2022 households: 7893 | with VMT > 0: 6152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    HOUSEID   HH_VMT  HHSIZE  NUMVEH  HHFAMINC  URBAN  HOMEOWN  HH_RACE\n",
       " 0  30000007  180.518       3       5       7.0      1      1.0      2.0\n",
       " 1  30000008   16.034       2       4       8.0      4      1.0      1.0\n",
       " 2  30000012  126.817       1       2      10.0      1      1.0      1.0,\n",
       "       HOUSEID     HH_VMT  HHSIZE  NUMVEH  HHFAMINC  URBAN  HOMEOWN  HH_RACE\n",
       " 0  9000013002  51.533872       4       2      11.0      1        1        1\n",
       " 1  9000013016  21.866998       2       1       7.0      1        3        1\n",
       " 2  9000013026   0.000000       1       0      10.0      1        3        1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Cell 4: Load, create HH_VMT, and merge\n",
    "\n",
    "df_hh_2017 = normalize_household(PATH_HH_2017)\n",
    "df_hh_2022 = normalize_household(PATH_HH_2022)\n",
    "\n",
    "hh_vmt_2017 = trips_to_hh_vmt(PATH_TR_2017)\n",
    "hh_vmt_2022 = trips_to_hh_vmt(PATH_TR_2022)\n",
    "\n",
    "df_2017 = df_hh_2017.merge(hh_vmt_2017, on=\"HOUSEID\", how=\"left\")\n",
    "df_2022 = df_hh_2022.merge(hh_vmt_2022, on=\"HOUSEID\", how=\"left\")\n",
    "\n",
    "# Households with no recorded trips -> 0 VMT (common in NHTS)\n",
    "df_2017[\"HH_VMT\"] = df_2017[\"HH_VMT\"].fillna(0.0)\n",
    "df_2022[\"HH_VMT\"] = df_2022[\"HH_VMT\"].fillna(0.0)\n",
    "\n",
    "print(\"2017 households:\", len(df_2017), \"| with VMT > 0:\", int((df_2017['HH_VMT'] > 0).sum()))\n",
    "print(\"2022 households:\", len(df_2022), \"| with VMT > 0:\", int((df_2022['HH_VMT'] > 0).sum()))\n",
    "\n",
    "# Quick peek\n",
    "display_cols = [\"HOUSEID\",\"HH_VMT\"] + [c for c in CANON if c in df_2017.columns][:6]\n",
    "df_2017.head(3)[display_cols], df_2022.head(3)[display_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e273a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filter -> 2017: 117192 | 2022: 6152\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 5: Filter out zero-VMT households\n",
    "\n",
    "FILTER_ZERO_VMT = True\n",
    "\n",
    "if FILTER_ZERO_VMT:\n",
    "    df_2017_nonzero = df_2017[df_2017[\"HH_VMT\"] > 0].copy()\n",
    "    df_2022_nonzero = df_2022[df_2022[\"HH_VMT\"] > 0].copy()\n",
    "else:\n",
    "    df_2017_nonzero = df_2017.copy()\n",
    "    df_2022_nonzero = df_2022.copy()\n",
    "\n",
    "print(f\"After filter -> 2017: {len(df_2017_nonzero)} | 2022: {len(df_2022_nonzero)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d6bb7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: ['HHSIZE', 'NUMVEH', 'HHFAMINC', 'URBAN', 'HOMEOWN', 'HH_RACE', 'HH_HISP']\n",
      "Categorical: ['HHFAMINC', 'URBAN', 'HOMEOWN', 'HH_RACE', 'HH_HISP'] | Numeric: ['HHSIZE', 'NUMVEH']\n",
      "Missing in 2017: ['HOMETYPE']\n",
      "Missing in 2022: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell 6: Feature intersection & preprocessing\n",
    "\n",
    "CANDIDATE_FEATURES = CANON.copy()\n",
    "CAT_CANDS = [\"HHFAMINC\",\"URBAN\",\"HOMEOWN\",\"HOMETYPE\",\"HH_RACE\",\"HH_HISP\"]\n",
    "NUM_CANDS = [\"HHSIZE\",\"NUMVEH\"]\n",
    "\n",
    "present_2017 = [c for c in CANDIDATE_FEATURES if c in df_2017_nonzero.columns]\n",
    "present_2022 = [c for c in CANDIDATE_FEATURES if c in df_2022_nonzero.columns]\n",
    "COMMON_FEATURES = [c for c in CANDIDATE_FEATURES if c in present_2017 and c in present_2022]\n",
    "\n",
    "if not COMMON_FEATURES:\n",
    "    raise ValueError(\"No overlapping features between 2017 and 2022 after cleaning.\")\n",
    "\n",
    "cat_cols = [c for c in CAT_CANDS if c in COMMON_FEATURES]\n",
    "num_cols = [c for c in NUM_CANDS if c in COMMON_FEATURES]\n",
    "\n",
    "print(\"Using features:\", COMMON_FEATURES)\n",
    "print(\"Categorical:\", cat_cols or \"[]\", \"| Numeric:\", num_cols or \"[]\")\n",
    "print(\"Missing in 2017:\", [c for c in CANDIDATE_FEATURES if c not in present_2017])\n",
    "print(\"Missing in 2022:\", [c for c in CANDIDATE_FEATURES if c not in present_2022])\n",
    "\n",
    "# Prepare X/y\n",
    "X_train = df_2017_nonzero[COMMON_FEATURES].copy()\n",
    "X_test  = df_2022_nonzero[COMMON_FEATURES].copy()\n",
    "\n",
    "for c in cat_cols:\n",
    "    X_train[c] = X_train[c].astype(\"category\")\n",
    "    X_test[c] = X_test[c].astype(\"category\")\n",
    "\n",
    "y_train = np.log1p(df_2017_nonzero[\"HH_VMT\"].clip(lower=0))\n",
    "y_test  = np.log1p(df_2022_nonzero[\"HH_VMT\"].clip(lower=0))\n",
    "y_test_orig = df_2022_nonzero[\"HH_VMT\"].values\n",
    "\n",
    "# Preprocess\n",
    "transformers = []\n",
    "if cat_cols:\n",
    "    transformers.append((\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols))\n",
    "if num_cols:\n",
    "    transformers.append((\"num\", StandardScaler(), num_cols))\n",
    "\n",
    "pre = ColumnTransformer(transformers, remainder=\"drop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc8ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 7: Train & evaluate models with smearing correction\n",
    "\n",
    "models = {\n",
    "    \"Linear\": LinearRegression(),\n",
    "    \"RF\": RandomForestRegressor(n_estimators=300, random_state=RANDOM_STATE, n_jobs=-1),\n",
    "}\n",
    "\n",
    "if XGBRegressor is not None:\n",
    "    models[\"XGB\"] = XGBRegressor(\n",
    "        n_estimators=400, max_depth=6, learning_rate=0.07,\n",
    "        subsample=0.8, colsample_bytree=0.8, random_state=RANDOM_STATE, tree_method=\"hist\"\n",
    "    )\n",
    "\n",
    "results = {}\n",
    "for name, reg in models.items():\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"reg\", reg)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Smearing correction using train residual variance\n",
    "    y_pred_log_test  = pipe.predict(X_test)\n",
    "    y_pred_log_train = pipe.predict(X_train)\n",
    "    sigma2 = float(np.var(y_train - y_pred_log_train))\n",
    "    y_pred_orig = np.expm1(y_pred_log_test + 0.5 * sigma2)\n",
    "\n",
    "    # Metrics\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_test_orig, y_pred_orig)))\n",
    "    mae  = float(mean_absolute_error(y_test_orig, y_pred_orig))\n",
    "    r2   = float(r2_score(y_test_orig, y_pred_orig))\n",
    "\n",
    "    # Record\n",
    "    k_feats = int(pipe.named_steps[\"pre\"].transform(X_train.head(1)).shape[1])\n",
    "    results[name] = {\"pipeline\": pipe, \"RMSE\": rmse, \"MAE\": mae, \"R2\": r2, \"sigma2\": sigma2, \"k_feats\": k_feats}\n",
    "\n",
    "for name, r in results.items():\n",
    "    print(f\"{name:<6} RMSE: {r['RMSE']:.2f}  MAE: {r['MAE']:.2f}  R²: {r['R2']:.4f}  (k={r['k_feats']})\")\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cbafa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 8: XGBoost feature importances and plot\n",
    "\n",
    "def get_feature_names_from_column_transformer(ct):\n",
    "    out = []\n",
    "    for name, trans, cols in ct.transformers_:\n",
    "        if name == \"remainder\":\n",
    "            continue\n",
    "        if hasattr(trans, \"get_feature_names_out\"):\n",
    "            out.extend(list(trans.get_feature_names_out(cols)))\n",
    "        else:\n",
    "            out.extend(cols)\n",
    "    return out\n",
    "\n",
    "if \"XGB\" in results:\n",
    "    xgb_pipe = results[\"XGB\"][\"pipeline\"]\n",
    "    feat_names = get_feature_names_from_column_transformer(xgb_pipe.named_steps[\"pre\"])\n",
    "    importances = xgb_pipe.named_steps[\"reg\"].feature_importances_\n",
    "    feat_imp_df = pd.DataFrame({\"feature\": feat_names, \"importance\": importances})                     .sort_values(\"importance\", ascending=False)\n",
    "    display(feat_imp_df.head(20))\n",
    "\n",
    "    # Plot top 15\n",
    "    topN = 15\n",
    "    plt.figure(figsize=(8,6))\n",
    "    feat_imp_df.head(topN).iloc[::-1].plot(kind=\"barh\", x=\"feature\", y=\"importance\", legend=False)\n",
    "    plt.title(\"Top XGBoost Feature Importances\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"XGBoost not available. Skipping feature importances.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0223b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 9: Residual analysis (using best model by R²)\n",
    "\n",
    "# Pick best model\n",
    "best_name = max(results.items(), key=lambda kv: kv[1][\"R2\"])[0]\n",
    "best_pipe = results[best_name][\"pipeline\"]\n",
    "\n",
    "y_pred_log_test  = best_pipe.predict(X_test)\n",
    "sigma2_best = results[best_name][\"sigma2\"]\n",
    "y_pred_orig = np.expm1(y_pred_log_test + 0.5 * sigma2_best)\n",
    "\n",
    "residuals = y_test_orig - y_pred_orig\n",
    "abs_err = np.abs(residuals)\n",
    "\n",
    "print(f\"Best model: {best_name}\")\n",
    "print(pd.Series(residuals).describe())\n",
    "\n",
    "# Residual vs. predicted plot\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(y_pred_orig, residuals, alpha=0.3, s=8)\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.xlabel(\"Predicted HH_VMT\")\n",
    "plt.ylabel(\"Residual (y - y_pred)\")\n",
    "plt.title(\"Residuals vs Predicted\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residual distribution\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.hist(residuals, bins=50)\n",
    "plt.title(\"Residual Distribution\")\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dbccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 10: Segment analysis (income, urban, vehicle count)\n",
    "\n",
    "anal_df = df_2022_nonzero.copy()\n",
    "anal_df = anal_df.assign(y_true=y_test_orig, y_pred=y_pred_orig, abs_err=abs_err)\n",
    "\n",
    "def metric_table(df, key):\n",
    "    g = df.groupby(key).agg(\n",
    "        n=(\"HOUSEID\",\"count\"),\n",
    "        rmse=(\"abs_err\", lambda x: np.sqrt(np.mean((x**2)))),\n",
    "        mae=(\"abs_err\",\"mean\")\n",
    "    ).reset_index().sort_values(\"rmse\")\n",
    "    return g\n",
    "\n",
    "# Income\n",
    "if \"HHFAMINC\" in anal_df.columns:\n",
    "    print(\"By HHFAMINC:\")\n",
    "    display(metric_table(anal_df, \"HHFAMINC\").head(20))\n",
    "\n",
    "# Urban\n",
    "if \"URBAN\" in anal_df.columns:\n",
    "    print(\"By URBAN:\")\n",
    "    display(metric_table(anal_df, \"URBAN\"))\n",
    "\n",
    "# Vehicles\n",
    "if \"NUMVEH\" in anal_df.columns:\n",
    "    bins = pd.cut(anal_df[\"NUMVEH\"], bins=[-0.1,0.5,1.5,2.5,10], labels=[\"0\",\"1\",\"2\",\"3+\"])\n",
    "    anal_df[\"NUMVEH_BIN\"] = bins\n",
    "    print(\"By NUMVEH_BIN:\")\n",
    "    display(metric_table(anal_df, \"NUMVEH_BIN\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563812dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 11 : HistGradientBoosting with Poisson loss on original scale\n",
    "# Poisson is often better for non-negative, skewed targets (like miles).\n",
    "\n",
    "if HistGradientBoostingRegressor is not None:\n",
    "    # Train on original (non-log) target\n",
    "    y_train_poiss = df_2017_nonzero[\"HH_VMT\"].clip(lower=0)\n",
    "    y_test_poiss  = df_2022_nonzero[\"HH_VMT\"].clip(lower=0)\n",
    "\n",
    "    # Reuse preprocessing\n",
    "    pipe_poiss = Pipeline([(\"pre\", pre),\n",
    "                           (\"reg\", HistGradientBoostingRegressor(loss=\"poisson\",\n",
    "                                                                 learning_rate=0.07,\n",
    "                                                                 max_depth=6,\n",
    "                                                                 max_iter=500,\n",
    "                                                                 random_state=RANDOM_STATE))])\n",
    "    pipe_poiss.fit(X_train, y_train_poiss)\n",
    "    y_pred_poiss = pipe_poiss.predict(X_test)\n",
    "\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_test_poiss, y_pred_poiss)))\n",
    "    mae  = float(mean_absolute_error(y_test_poiss, y_pred_poiss))\n",
    "    r2   = float(r2_score(y_test_poiss, y_pred_poiss))\n",
    "    print(f\"HGB-Poisson  RMSE: {rmse:.2f}  MAE: {mae:.2f}  R²: {r2:.4f}\")\n",
    "else:\n",
    "    print(\"HistGradientBoostingRegressor not available. Skipping Poisson test.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
